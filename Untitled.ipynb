{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad04a6af-ec88-4260-981b-61f94a1aa48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.api import OLS\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d8ccbc1-bbde-41a4-9cf6-42cec3c7cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e7957f2-09a4-43d3-b6f7-f4dc479ad208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(data, features):\n",
    "    for feature in features:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Boxplot for outlier detection\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.boxplot(data[feature])\n",
    "        plt.title(f'Boxplot of {feature}')\n",
    "\n",
    "        # Histogram for distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.histplot(data[feature], kde=True)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31d610db-dd6c-49d4-94d8-2ac0df2ba1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(residuals, y_pred):\n",
    "    plt.scatter(y_pred, residuals)\n",
    "    plt.title('Residuals vs. Predicted Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1be8e7ef-6633-4627-9696-c9e68d5eebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normality(residuals):\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title('Normal Q-Q plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e2e1238-29c1-4803-ba7d-126cf639702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, features, imputer):\n",
    "    data[features] = imputer.transform(data[features])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "94c524d0-c521-46c2-8882-003565fe51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_statsmodels(X, y):\n",
    "    X = sm.add_constant(X)  # Adding a constant to the model\n",
    "    model = sm.OLS(y, X).fit(cov_type='HC0')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e8f89d0-94b0-4660-a48c-18f39993dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Paths to the datasets\n",
    "    train_path = 'train.csv'\n",
    "    test_path = 'test.csv'\n",
    "    \n",
    "    # Load the data\n",
    "    train_data, test_data = load_data(train_path, test_path)\n",
    "\n",
    "    #convert categorical variable into dummy\n",
    "    train_data = pd.get_dummies(train_data)\n",
    "    test_data = pd.get_dummies(test_data)\n",
    "    \n",
    "    # Visualize data\n",
    "    selected_features = ['LotArea','YrSold', 'OverallQual', 'OverallCond', 'GrLivArea', 'TotalBsmtSF','GarageCars', 'MSSubClass', 'YearBuilt', 'Hearing']\n",
    "    #visualize_data(train_data, selected_features)\n",
    "    \n",
    "    # Handling missing values\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    train_data[selected_features] = imputer.fit_transform(train_data[selected_features])\n",
    " \n",
    "    # Apply log transformation to the target variable 'SalePrice'\n",
    "    train_data['SalePrice'] = np.log1p(train_data['SalePrice'])\n",
    "    y = train_data['SalePrice']\n",
    "    \n",
    "    # Splitting the train data into X (features) and y (target)\n",
    "    X = train_data[selected_features]\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    # Splitting the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_poly, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Training the models\n",
    "    model = train_model_statsmodels(X_train, y_train)\n",
    "    \n",
    "    # Evaluating the model\n",
    "    X_val = sm.add_constant(X_val)  # Adding a constant to the validation data\n",
    "    y_pred_log =model.predict(X_val)  # Predicted log-transformed prices\n",
    "    y_pred = np.expm1(y_pred_log)  # Inverse transformation\n",
    "    r_squared = r2_score(np.expm1(y_val), y_pred)\n",
    "    residuals = np.expm1(y_val) - y_pred\n",
    "    #plot_residuals(residuals, y_pred)\n",
    "    #normality(residuals)\n",
    "    print(\"R-squared value:\", r_squared)\n",
    "    \n",
    "    # Preprocessing the test data\n",
    "    test_data = preprocess_data(test_data, selected_features, imputer)\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_test = poly.fit_transform(test_data[selected_features])\n",
    "        \n",
    "    # Predicting the housing prices for the test data\n",
    "    X_test = sm.add_constant(X_test)  # Adding a constant to the test data\n",
    "    predicted_log_prices = model.predict(X_test)  # Predicted log-transformed prices for test data\n",
    "    predicted_prices = np.expm1(predicted_log_prices)  # Inverse transformation for test data predictions\n",
    "    ''\n",
    "    # Saving the predictions\n",
    "    predicted_prices_df = pd.DataFrame({\n",
    "        'Id': test_data['Id'],\n",
    "        'SalePrice': predicted_prices\n",
    "    })\n",
    "    predicted_prices_df.to_csv('predicted_housing_prices_statsmodels.csv', index=False)\n",
    "    ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "25f8d0b9-738a-4e79-92cd-4a2ca1e2e72b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Hearing'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[37], line 27\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m y \u001b[38;5;241m=\u001b[39m train_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalePrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Splitting the train data into X (features) and y (target)\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mselected_features\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Polynomial features\u001b[39;00m\n\u001b[0;32m     30\u001b[0m poly \u001b[38;5;241m=\u001b[39m PolynomialFeatures(degree\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, include_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4096\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4094\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4095\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4096\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4098\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6199\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6197\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6201\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6203\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6251\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6250\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6251\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Hearing'] not in index\""
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
