{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "ad04a6af-ec88-4260-981b-61f94a1aa48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.api import OLS\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "7d8ccbc1-bbde-41a4-9cf6-42cec3c7cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "7e7957f2-09a4-43d3-b6f7-f4dc479ad208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(data, features):\n",
    "    for feature in features:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Boxplot for outlier detection\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.boxplot(data[feature])\n",
    "        plt.title(f'Boxplot of {feature}')\n",
    "\n",
    "        # Histogram for distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.histplot(data[feature], kde=True)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "31d610db-dd6c-49d4-94d8-2ac0df2ba1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(residuals, y_pred):\n",
    "    plt.scatter(y_pred, residuals)\n",
    "    plt.title('Residuals vs. Predicted Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "1be8e7ef-6633-4627-9696-c9e68d5eebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normality(residuals):\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title('Normal Q-Q plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "id": "3e2e1238-29c1-4803-ba7d-126cf639702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, features, imputer):\n",
    "    data[features] = imputer.transform(data[features])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "94c524d0-c521-46c2-8882-003565fe51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_statsmodels(X, y):\n",
    "    X = sm.add_constant(X)  # Adding a constant to the model\n",
    "    model = sm.OLS(y, X).fit(cov_type='HC0')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "id": "0ff54f4a-5f4f-4db0-8ad1-903c5d2e9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, A, b, k):\n",
    "    cv_scores = cross_val_score(x, A, b, cv=k, scoring='r2')\n",
    "    average_score = cv_scores.mean()\n",
    "    print(\"cv score:\", average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "id": "7e8f89d0-94b0-4660-a48c-18f39993dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Paths to the datasets\n",
    "    train_path = 'train.csv'\n",
    "    test_path = 'test.csv'\n",
    "    \n",
    "    # Load the data\n",
    "    train_data, test_data = load_data(train_path, test_path)\n",
    "\n",
    "    #convert categorical variable into dummy\n",
    "    train_data = pd.get_dummies(train_data)\n",
    "    test_data = pd.get_dummies(test_data)\n",
    "    \n",
    "    # Visualize data\n",
    "    selected_features = ['LotArea','YrSold', 'OverallQual', 'GrLivArea', 'TotalBsmtSF','GarageCars', 'MSSubClass', 'YearBuilt']\n",
    "    #visualize_data(train_data, selected_features)\n",
    "    \n",
    "    # Handling missing values\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    train_data[selected_features] = imputer.fit_transform(train_data[selected_features])\n",
    " \n",
    "    # Apply log transformation to the target variable 'SalePrice'\n",
    "    train_data['SalePrice'] = np.log(train_data['SalePrice'])\n",
    "    y = train_data['SalePrice']\n",
    "    \n",
    "    # Splitting the train data into X (features) and y (target)\n",
    "    X = train_data[selected_features]\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    # Splitting the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_poly, y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # Training the models\n",
    "    statsmodels = train_model_statsmodels(X_train, y_train)\n",
    "    lasso = make_pipeline(RobustScaler().fit(X_train, y_train), Lasso(alpha =0.0005, random_state=1))\n",
    "    ENet = make_pipeline(RobustScaler().fit(X_train, y_train), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "    \n",
    "    class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "        def __init__(self, models):\n",
    "            self.models_ = models\n",
    "        \n",
    "        # we define clones of the original models to fit the data in\n",
    "        def fit(self, X_train, y_train):\n",
    "            self.models_ = [clone(x) for x in self.models_]\n",
    "        \n",
    "            # Train cloned base models\n",
    "            for model in self.models_:\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "            return self\n",
    "    \n",
    "        #Now we do the predictions for cloned models and average them\n",
    "        def predict(self, X_val):\n",
    "            predictions = np.column_stack([\n",
    "                model.predict(X_val) for model in self.models_\n",
    "            ])\n",
    "            return np.mean(predictions, axis=1)\n",
    "      \n",
    "    averaged_models = AveragingModels(models = (ENet, statsmodels, lasso))\n",
    "    \n",
    "    # Evaluating the model\n",
    "    X_val = sm.add_constant(X_val)  # Adding a constant to the validation data\n",
    "    y_pred_log = averaged_models.predict(X_val)  # Predicted log-transformed prices\n",
    "    y_pred = np.exp(y_pred_log)  # Inverse transformation\n",
    "    r_squared = r2_score(np.exp(y_val), y_pred)\n",
    "    residuals = np.exp(y_val) - y_pred\n",
    "    #plot_residuals(residuals, y_pred)\n",
    "    #normality(residuals)\n",
    "    print(\"R-squared value:\", r_squared)\n",
    "    \n",
    "    # Preprocessing the test data\n",
    "    test_data = preprocess_data(test_data, selected_features, imputer)\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_test = poly.fit_transform(test_data[selected_features])\n",
    "        \n",
    "    # Predicting the housing prices for the test data\n",
    "    X_test = sm.add_constant(X_test)  # Adding a constant to the test data\n",
    "    predicted_log_prices = statsmodels.predict(X_test)  # Predicted log-transformed prices for test data\n",
    "    predicted_prices = np.exp(predicted_log_prices)  # Inverse transformation for test data predictions\n",
    "    ''\n",
    "    # Saving the predictions\n",
    "    predicted_prices_df = pd.DataFrame({\n",
    "        'Id': test_data['Id'],\n",
    "        'SalePrice': predicted_prices\n",
    "    })\n",
    "    predicted_prices_df.to_csv('predicted_housing_prices_statsmodels.csv', index=False)\n",
    "    ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "id": "25f8d0b9-738a-4e79-92cd-4a2ca1e2e72b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This ElasticNet instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[783], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[782], line 65\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Evaluating the model\u001b[39;00m\n\u001b[0;32m     64\u001b[0m X_val \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_val)  \u001b[38;5;66;03m# Adding a constant to the validation data\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m y_pred_log \u001b[38;5;241m=\u001b[39m \u001b[43maveraged_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Predicted log-transformed prices\u001b[39;00m\n\u001b[0;32m     66\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(y_pred_log)  \u001b[38;5;66;03m# Inverse transformation\u001b[39;00m\n\u001b[0;32m     67\u001b[0m r_squared \u001b[38;5;241m=\u001b[39m r2_score(np\u001b[38;5;241m.\u001b[39mexp(y_val), y_pred)\n",
      "Cell \u001b[1;32mIn[782], line 56\u001b[0m, in \u001b[0;36mmain.<locals>.AveragingModels.predict\u001b[1;34m(self, X_val)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_val):\n\u001b[1;32m---> 56\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack(\u001b[43m[\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels_\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[1;32mIn[782], line 57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X_val):\n\u001b[0;32m     56\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([\n\u001b[1;32m---> 57\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels_\n\u001b[0;32m     58\u001b[0m     ])\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmean(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:603\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    602\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n\u001b[0;32m    606\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m process_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:286\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    273\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    Predict using the linear model.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03m        Returns predicted values.\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1116\u001b[0m, in \u001b[0;36mElasticNet._decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decision function of the linear model.\u001b[39;00m\n\u001b[0;32m   1106\u001b[0m \n\u001b[0;32m   1107\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;124;03m        The predicted decision function.\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1544\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1541\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This ElasticNet instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
