{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad04a6af-ec88-4260-981b-61f94a1aa48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin, clone\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.api import OLS\n",
    "from scipy.stats import norm\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7d8ccbc1-bbde-41a4-9cf6-42cec3c7cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path, test_path):\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e7957f2-09a4-43d3-b6f7-f4dc479ad208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data(data, features):\n",
    "    for feature in features:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Boxplot for outlier detection\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.boxplot(data[feature])\n",
    "        plt.title(f'Boxplot of {feature}')\n",
    "\n",
    "        # Histogram for distribution\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.histplot(data[feature], kde=True)\n",
    "        plt.title(f'Distribution of {feature}')\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "31d610db-dd6c-49d4-94d8-2ac0df2ba1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(residuals, y_pred):\n",
    "    plt.scatter(y_pred, residuals)\n",
    "    plt.title('Residuals vs. Predicted Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Residuals')\n",
    "    plt.axhline(y=0, color='r', linestyle='--')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1be8e7ef-6633-4627-9696-c9e68d5eebbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normality(residuals):\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=plt)\n",
    "    plt.title('Normal Q-Q plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3e2e1238-29c1-4803-ba7d-126cf639702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, features, imputer):\n",
    "    data[features] = imputer.transform(data[features])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "94c524d0-c521-46c2-8882-003565fe51ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_statsmodels(X, y):\n",
    "    X = sm.add_constant(X)  # Adding a constant to the model\n",
    "    model = sm.OLS(y, X).fit(cov_type='HC0')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ff54f4a-5f4f-4db0-8ad1-903c5d2e9060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, A, b, k):\n",
    "    cv_scores = cross_val_score(x, A, b, cv=k, scoring='r2')\n",
    "    average_score = cv_scores.mean()\n",
    "    print(\"cv score:\", average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7e8f89d0-94b0-4660-a48c-18f39993dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Paths to the datasets\n",
    "    train_path = 'train.csv'\n",
    "    test_path = 'test.csv'\n",
    "    \n",
    "    # Load the data\n",
    "    train_data, test_data = load_data(train_path, test_path)\n",
    "\n",
    "    #convert categorical variable into dummy\n",
    "    train_data = pd.get_dummies(train_data)\n",
    "    test_data = pd.get_dummies(test_data)\n",
    "    \n",
    "    # Visualize data\n",
    "    selected_features = ['LotArea','YrSold', 'OverallQual', 'GrLivArea', 'TotalBsmtSF','GarageCars', 'MSSubClass', 'YearBuilt']\n",
    "    #visualize_data(train_data, selected_features)\n",
    "    \n",
    "    # Handling missing values\n",
    "    imputer = SimpleImputer(strategy='constant', fill_value=0)\n",
    "    train_data[selected_features] = imputer.fit_transform(train_data[selected_features])\n",
    " \n",
    "    # Apply log transformation to the target variable 'SalePrice'\n",
    "    train_data['SalePrice'] = np.log1p(train_data['SalePrice'])\n",
    "    y = train_data['SalePrice']\n",
    "    \n",
    "    # Splitting the train data into X (features) and y (target)\n",
    "    X = train_data[selected_features]\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    # Splitting the data into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_poly, y, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Standardize the features\n",
    "    #scaler = StandardScaler()\n",
    "    #X_train_scaled = scaler.fit_transform(X_train)\n",
    "    #X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "    # Initialize models\n",
    "    lr = LinearRegression()\n",
    "    enet = ElasticNet(random_state=42)\n",
    "    lasso = Lasso(random_state=42)\n",
    "    ridge = Ridge(random_state=42)\n",
    "\n",
    "    # Train individual models\n",
    "    statsmodels = train_model_statsmodels(X_train, y_train)\n",
    "    lr.fit(X_train, y_train)\n",
    "    enet.fit(X_train, y_train)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    ridge.fit(X_train, y_train)\n",
    "\n",
    "    # Stacking models\n",
    "    estimators = [\n",
    "        ('lr', lr),\n",
    "        ('sm', statsmodels),\n",
    "        ('enet', enet),\n",
    "        ('lasso', lasso),\n",
    "        ('ridge', ridge)\n",
    "    ]\n",
    "    stacked_model = StackingRegressor(estimators=estimators, final_estimator=LinearRegression())\n",
    "\n",
    "    # Train stacked model\n",
    "    stacked_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Training the models\n",
    "    #model = train_model_statsmodels(X_train, y_train)\n",
    "    \n",
    "    # Evaluating the model\n",
    "    X_val = sm.add_constant(X_val)  # Adding a constant to the validation data\n",
    "    y_pred_log =stacked_model.predict(X_val)  # Predicted log-transformed prices\n",
    "    y_pred = np.expm1(y_pred_log)  # Inverse transformation\n",
    "    r_squared = r2_score(np.expm1(y_val), y_pred)\n",
    "    residuals = np.expm1(y_val) - y_pred\n",
    "    #plot_residuals(residuals, y_pred)\n",
    "    #normality(residuals)\n",
    "    print(\"R-squared value:\", r_squared)\n",
    "    \n",
    "    # Preprocessing the test data\n",
    "    test_data = preprocess_data(test_data, selected_features, imputer)\n",
    "    \n",
    "    # Polynomial features\n",
    "    poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "    X_test = poly.fit_transform(test_data[selected_features])\n",
    "        \n",
    "    # Predicting the housing prices for the test data\n",
    "    X_test = sm.add_constant(X_test)  # Adding a constant to the test data\n",
    "    predicted_log_prices = stacked_model.predict(X_test)  # Predicted log-transformed prices for test data\n",
    "    predicted_prices = np.expm1(predicted_log_prices)  # Inverse transformation for test data predictions\n",
    "    ''\n",
    "    # Saving the predictions\n",
    "    predicted_prices_df = pd.DataFrame({\n",
    "        'Id': test_data['Id'],\n",
    "        'SalePrice': predicted_prices\n",
    "    })\n",
    "    predicted_prices_df.to_csv('predicted_housing_prices_statsmodels.csv', index=False)\n",
    "    ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25f8d0b9-738a-4e79-92cd-4a2ca1e2e72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mustafa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.56634e-22): result may not be accurate.\n",
      "  return linalg.solve(A, Xy, assume_a=\"pos\", overwrite_a=True).T\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The estimator RegressionResultsWrapper should be a regressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[82], line 64\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m stacked_model \u001b[38;5;241m=\u001b[39m StackingRegressor(estimators\u001b[38;5;241m=\u001b[39mestimators, final_estimator\u001b[38;5;241m=\u001b[39mLinearRegression())\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Train stacked model\u001b[39;00m\n\u001b[1;32m---> 64\u001b[0m \u001b[43mstacked_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Training the models\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#model = train_model_statsmodels(X_train, y_train)\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Evaluating the model\u001b[39;00m\n\u001b[0;32m     70\u001b[0m X_val \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39madd_constant(X_val)  \u001b[38;5;66;03m# Adding a constant to the validation data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:962\u001b[0m, in \u001b[0;36mStackingRegressor.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    960\u001b[0m _raise_for_unsupported_routing(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[0;32m    961\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_stacking.py:195\u001b[0m, in \u001b[0;36m_BaseStacking.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the estimators.\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mself : object\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;66;03m# all_estimators contains all estimators, the one to be fitted and the\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# 'drop' string.\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m names, all_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_estimators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_final_estimator()\n\u001b[0;32m    198\u001b[0m stack_method \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack_method] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_estimators)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:236\u001b[0m, in \u001b[0;36m_BaseHeterogeneousEnsemble._validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m est \u001b[38;5;129;01min\u001b[39;00m estimators:\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m est \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_estimator_type(est):\n\u001b[1;32m--> 236\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    237\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe estimator \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m should be a \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    238\u001b[0m                 est\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, is_estimator_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m[\u001b[38;5;241m3\u001b[39m:]\n\u001b[0;32m    239\u001b[0m             )\n\u001b[0;32m    240\u001b[0m         )\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m names, estimators\n",
      "\u001b[1;31mValueError\u001b[0m: The estimator RegressionResultsWrapper should be a regressor."
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932297d0-1376-4998-bd6c-255bffd677a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
